# ğŸ¦ íˆ¬ìì ë™í–¥ MCP ì„œë²„ ê°œë°œ ê³„íšì„œ

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©ì 
í•œêµ­ ì£¼ì‹ì‹œì¥ì˜ íˆ¬ììë³„(ì™¸êµ­ì¸/ê¸°ê´€/ê°œì¸) ë§¤ë§¤ ë™í–¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” MCP ì„œë²„ êµ¬ì¶•

### 1.2 ë²”ìœ„
- íˆ¬ììë³„ ìˆœë§¤ìˆ˜/ë§¤ë„ ë™í–¥
- í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë¶„ì„
- íˆ¬ììë³„ ë³´ìœ  ë¹„ì¤‘ ì¶”ì 
- ì—…ì¢…ë³„ íˆ¬ìì ë™í–¥
- ì‹œê°„ëŒ€ë³„ ë§¤ë§¤ íŒ¨í„´ ë¶„ì„
- íˆ¬ì ì£¼ì²´ë³„ ì„ í˜¸ ì¢…ëª© ë¶„ì„
- ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì 

### 1.3 ê¸°ìˆ  ìŠ¤íƒ
- **ì–¸ì–´**: Python 3.11+
- **MCP SDK**: mcp-python
- **API Client**: í•œêµ­íˆ¬ìì¦ê¶Œ OpenAPI, ì´ë² ìŠ¤íŠ¸íˆ¬ìì¦ê¶Œ xingAPI
- **ë¹„ë™ê¸° ì²˜ë¦¬**: asyncio, aiohttp
- **ë°ì´í„° ë¶„ì„**: pandas, numpy
- **ì‹œê³„ì—´ ë¶„ì„**: statsmodels
- **ìºì‹±**: Redis + ë©”ëª¨ë¦¬ ìºì‹œ
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL + TimescaleDB

## 2. ì„œë²„ ì•„í‚¤í…ì²˜

```
mcp-investor-trends/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.py                    # MCP ì„œë²„ ë©”ì¸
â”‚   â”œâ”€â”€ tools/                       # MCP ë„êµ¬ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ investor_tools.py       # íˆ¬ìì ë™í–¥ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ program_tools.py        # í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ ownership_tools.py      # ë³´ìœ  ë¹„ì¤‘ ë„êµ¬
â”‚   â”‚   â””â”€â”€ analysis_tools.py       # ë¶„ì„ ë„êµ¬
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ korea_investment.py     # í•œíˆ¬ API
â”‚   â”‚   â”œâ”€â”€ ebest.py                # ì´ë² ìŠ¤íŠ¸ API
â”‚   â”‚   â”œâ”€â”€ models.py               # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â””â”€â”€ constants.py            # ìƒìˆ˜ ì •ì˜
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ investor_analyzer.py    # íˆ¬ìì ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ flow_analyzer.py        # ìê¸ˆ íë¦„ ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py     # íŒ¨í„´ ê°ì§€
â”‚   â”‚   â””â”€â”€ smart_money.py          # ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì 
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ cache.py                # ìºì‹œ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ database.py             # DB ì—°ê²°
â”‚   â”‚   â”œâ”€â”€ calculator.py           # ê³„ì‚° ìœ í‹¸
â”‚   â”‚   â””â”€â”€ formatter.py            # í¬ë§·íŒ…
â”‚   â”œâ”€â”€ config.py                   # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ exceptions.py               # ì˜ˆì™¸ ì •ì˜
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## 3. í•µì‹¬ ê¸°ëŠ¥ ëª…ì„¸

### 3.1 ì œê³µ ë„êµ¬ (Tools)

#### 1) `get_investor_trading`
```python
@tool
async def get_investor_trading(
    stock_code: Optional[str] = None,
    investor_type: Literal["FOREIGN", "INSTITUTION", "INDIVIDUAL", "ALL"] = "ALL",
    period: Literal["1D", "5D", "20D", "60D"] = "1D",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    include_details: bool = True
) -> dict:
    """
    íˆ¬ììë³„ ë§¤ë§¤ ë™í–¥ ì¡°íšŒ
    
    Parameters:
        stock_code: íŠ¹ì • ì¢…ëª© ì½”ë“œ (Noneì´ë©´ ì‹œì¥ ì „ì²´)
        investor_type: íˆ¬ìì ìœ í˜•
        period: ì¡°íšŒ ê¸°ê°„
        market: ì‹œì¥ êµ¬ë¶„
        include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "scope": "MARKET" or "STOCK",
            "stock_info": {  # stock_codeê°€ ìˆì„ ë•Œë§Œ
                "code": "005930",
                "name": "ì‚¼ì„±ì „ì",
                "current_price": 78500,
                "change_rate": 1.55
            },
            "investor_data": {
                "foreign": {
                    "buy_amount": 523456789000,
                    "sell_amount": 234567890000,
                    "net_amount": 288888899000,
                    "buy_volume": 6678900,
                    "sell_volume": 2987650,
                    "net_volume": 3691250,
                    "average_buy_price": 78350,
                    "average_sell_price": 78520,
                    "net_ratio": 55.2,  # ìˆœë§¤ìˆ˜ ë¹„ìœ¨
                    "trend": "ACCUMULATING",  # ë§¤ì§‘/ë¶„ì‚°
                    "intensity": 8.5  # ë§¤ë§¤ ê°•ë„ (1-10)
                },
                "institution": {
                    "buy_amount": 345678900000,
                    "sell_amount": 456789000000,
                    "net_amount": -111110100000,
                    "sub_categories": {  # ê¸°ê´€ ì„¸ë¶€
                        "investment_trust": 23456789000,
                        "pension_fund": -34567890000,
                        "insurance": 12345678000,
                        "private_fund": -45678900000,
                        "bank": 23456789000,
                        "other": -12345678000
                    }
                },
                "individual": {...},
                "program": {
                    "total_buy": 123456789000,
                    "total_sell": 98765432000,
                    "arbitrage_buy": 45678900000,
                    "arbitrage_sell": 34567890000,
                    "non_arbitrage_buy": 77777889000,
                    "non_arbitrage_sell": 64197542000
                }
            },
            "market_impact": {
                "price_correlation": 0.75,  # ê°€ê²©ê³¼ì˜ ìƒê´€ê´€ê³„
                "volume_contribution": 23.5,  # ê±°ë˜ëŸ‰ ê¸°ì—¬ë„
                "momentum_score": 7.2
            },
            "historical_comparison": {
                "vs_yesterday": {
                    "foreign_net_change": 156789000000,
                    "institution_net_change": -98765432000
                },
                "vs_week_ago": {...},
                "vs_month_ago": {...}
            }
        }
    """
```

#### 2) `get_ownership_changes`
```python
@tool
async def get_ownership_changes(
    stock_code: str,
    investor_type: Literal["FOREIGN", "INSTITUTION", "ALL"] = "ALL",
    period: Literal["1M", "3M", "6M", "1Y"] = "3M",
    threshold: Optional[float] = 1.0  # ìµœì†Œ ë³€í™”ìœ¨
) -> dict:
    """
    íˆ¬ììë³„ ë³´ìœ  ë¹„ì¤‘ ë³€í™” ì¶”ì 
    
    Parameters:
        stock_code: ì¢…ëª© ì½”ë“œ
        investor_type: íˆ¬ìì ìœ í˜•
        period: ì¶”ì  ê¸°ê°„
        threshold: ìµœì†Œ ë³€í™”ìœ¨ í•„í„°
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "stock_info": {
                "code": "005930",
                "name": "ì‚¼ì„±ì „ì",
                "market_cap": 468923450000000
            },
            "ownership_data": {
                "current": {
                    "foreign": {
                        "shares": 3123456789,
                        "percentage": 52.34,
                        "value": 245234567890000
                    },
                    "institution": {
                        "shares": 1234567890,
                        "percentage": 20.67,
                        "value": 96987654321000,
                        "breakdown": {
                            "national_pension": 8.5,
                            "investment_trust": 5.2,
                            "insurance": 3.1,
                            "other": 3.87
                        }
                    },
                    "individual": {
                        "shares": 1598765432,
                        "percentage": 26.78,
                        "value": 125543210987000
                    },
                    "treasury": {
                        "shares": 12345678,
                        "percentage": 0.21
                    }
                },
                "changes": {
                    "foreign": {
                        "shares_change": 234567890,
                        "percentage_change": 2.34,
                        "value_change": 18423456789000,
                        "trend": "INCREASING",
                        "consecutive_days": 15
                    },
                    "institution": {...}
                },
                "historical": [
                    {
                        "date": "2024-01-01",
                        "foreign": 50.0,
                        "institution": 22.5,
                        "individual": 27.3
                    },
                    ...
                ],
                "milestones": [
                    {
                        "date": "2023-11-15",
                        "event": "ì™¸êµ­ì¸ ì§€ë¶„ 50% ëŒíŒŒ",
                        "foreign_ownership": 50.12
                    }
                ]
            },
            "correlation_analysis": {
                "price_vs_foreign_ownership": 0.82,
                "volatility_vs_ownership_change": -0.45,
                "ownership_concentration": 0.73  # í—ˆí•€ë‹¬ ì§€ìˆ˜
            }
        }
    """
```

#### 3) `get_program_trading`
```python
@tool
async def get_program_trading(
    market: Literal["KOSPI", "KOSDAQ", "ALL"] = "ALL",
    program_type: Literal["ALL", "ARBITRAGE", "NON_ARBITRAGE"] = "ALL",
    time_window: Literal["CURRENT", "1H", "TODAY"] = "CURRENT"
) -> dict:
    """
    í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë™í–¥ ì¡°íšŒ
    
    Parameters:
        market: ì‹œì¥ êµ¬ë¶„
        program_type: í”„ë¡œê·¸ë¨ ìœ í˜•
        time_window: ì‹œê°„ ë²”ìœ„
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "market": "ALL",
            "program_trading": {
                "summary": {
                    "total_buy": 234567890000,
                    "total_sell": 198765432000,
                    "net_value": 35802458000,
                    "buy_ratio": 54.1,  # ë§¤ìˆ˜ ë¹„ì¤‘
                    "market_impact": 12.3  # ì‹œì¥ ì˜í–¥ë„
                },
                "arbitrage": {
                    "buy": 123456789000,
                    "sell": 98765432000,
                    "net": 24691357000,
                    "basis": 2.5,  # ë² ì´ì‹œìŠ¤
                    "futures_position": "LONG",
                    "intensity": "HIGH"
                },
                "non_arbitrage": {
                    "buy": 111111101000,
                    "sell": 100000000000,
                    "net": 11111101000,
                    "strategy_breakdown": {
                        "index_tracking": 45678900000,
                        "etf_hedging": 34567890000,
                        "portfolio_rebalancing": 30864311000
                    }
                },
                "time_series": [
                    {
                        "time": "09:00",
                        "buy": 23456789000,
                        "sell": 19876543000,
                        "net": 3580246000,
                        "cumulative_net": 3580246000
                    },
                    ...
                ],
                "top_stocks": [
                    {
                        "code": "005930",
                        "name": "ì‚¼ì„±ì „ì",
                        "program_buy": 34567890000,
                        "program_sell": 23456789000,
                        "net": 11111101000,
                        "ratio": 15.2  # ì „ì²´ í”„ë¡œê·¸ë¨ ë§¤ë§¤ ì¤‘ ë¹„ì¤‘
                    },
                    ...
                ],
                "market_indicators": {
                    "program_participation_rate": 18.5,
                    "arbitrage_opportunity": "MODERATE",
                    "market_efficiency": 0.85
                }
            }
        }
    """
```

#### 4) `get_sector_investor_flow`
```python
@tool
async def get_sector_investor_flow(
    sector: Optional[str] = None,
    investor_type: Literal["FOREIGN", "INSTITUTION", "ALL"] = "ALL",
    period: Literal["1D", "5D", "20D"] = "5D",
    top_n: int = 10
) -> dict:
    """
    ì—…ì¢…ë³„ íˆ¬ìì ìê¸ˆ íë¦„ ë¶„ì„
    
    Parameters:
        sector: íŠ¹ì • ì—…ì¢… (Noneì´ë©´ ì „ì²´)
        investor_type: íˆ¬ìì ìœ í˜•
        period: ë¶„ì„ ê¸°ê°„
        top_n: ìƒìœ„ Nê°œ ì—…ì¢…
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "period": "5D",
            "sector_flows": [
                {
                    "sector_code": "G2510",
                    "sector_name": "ë°˜ë„ì²´",
                    "foreign": {
                        "net_amount": 1234567890000,
                        "buy_amount": 2345678900000,
                        "sell_amount": 1111111010000,
                        "net_ratio": 52.7,
                        "concentration": 0.75,  # íŠ¹ì • ì¢…ëª© ì§‘ì¤‘ë„
                        "top_stocks": [
                            {
                                "code": "005930",
                                "name": "ì‚¼ì„±ì „ì",
                                "net_amount": 987654321000,
                                "contribution": 80.0
                            },
                            ...
                        ]
                    },
                    "institution": {...},
                    "momentum": {
                        "score": 8.5,
                        "trend": "STRONG_BUY",
                        "consistency": 0.9  # ì¼ê´€ì„±
                    },
                    "sector_performance": {
                        "return": 5.67,
                        "vs_market": 3.21,
                        "correlation_with_flow": 0.78
                    }
                },
                ...
            ],
            "rotation_analysis": {
                "from_sectors": [
                    {"name": "ì€í–‰", "outflow": -234567890000}
                ],
                "to_sectors": [
                    {"name": "ë°˜ë„ì²´", "inflow": 345678900000}
                ],
                "rotation_strength": 7.5,
                "cycle_phase": "EARLY_CYCLE"
            },
            "market_overview": {
                "total_foreign_net": 2345678900000,
                "total_institution_net": -1234567890000,
                "sector_dispersion": 0.34,
                "concentration_risk": "MODERATE"
            }
        }
    """
```

#### 5) `get_time_based_flow`
```python
@tool
async def get_time_based_flow(
    stock_code: Optional[str] = None,
    interval: Literal["1M", "5M", "10M", "30M", "1H"] = "10M",
    session: Literal["ALL", "MORNING", "AFTERNOON"] = "ALL"
) -> dict:
    """
    ì‹œê°„ëŒ€ë³„ íˆ¬ìì ë§¤ë§¤ íŒ¨í„´ ë¶„ì„
    
    Parameters:
        stock_code: ì¢…ëª© ì½”ë“œ (Noneì´ë©´ ì‹œì¥ ì „ì²´)
        interval: ì‹œê°„ ê°„ê²©
        session: ì¥ ì‹œê°„ êµ¬ë¶„
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "analysis_scope": "STOCK" or "MARKET",
            "time_flow_data": [
                {
                    "time": "09:00",
                    "foreign": {
                        "buy": 123456789,
                        "sell": 98765432,
                        "net": 24691357,
                        "avg_price": 78450,
                        "intensity": 7.5
                    },
                    "institution": {...},
                    "individual": {...},
                    "price_impact": {
                        "open": 78000,
                        "close": 78500,
                        "change": 0.64,
                        "correlation": 0.82
                    }
                },
                ...
            ],
            "patterns": {
                "foreign": {
                    "typical_entry_time": "09:30-10:00",
                    "typical_exit_time": "14:30-15:00",
                    "morning_bias": "BUY",
                    "afternoon_bias": "NEUTRAL",
                    "consistency_score": 7.8
                },
                "institution": {
                    "batch_trading_times": ["09:00", "13:00", "14:50"],
                    "average_order_size": 234567890,
                    "execution_pattern": "VWAP"
                }
            },
            "anomalies": [
                {
                    "time": "10:30",
                    "type": "UNUSUAL_VOLUME",
                    "investor": "FOREIGN",
                    "magnitude": 345678900,
                    "z_score": 3.2
                }
            ],
            "optimal_trading_windows": {
                "low_impact": ["11:00-11:30", "13:30-14:00"],
                "high_liquidity": ["09:30-10:00", "14:30-15:00"],
                "foreign_active": ["09:30-10:30", "14:00-15:00"]
            }
        }
    """
```

#### 6) `get_smart_money_tracker`
```python
@tool
async def get_smart_money_tracker(
    detection_method: Literal["LARGE_ORDERS", "INSTITUTION_CLUSTER", "FOREIGN_SURGE"] = "LARGE_ORDERS",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    min_confidence: float = 7.0,
    count: int = 20
) -> dict:
    """
    ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì›€ì§ì„ ì¶”ì 
    
    Parameters:
        detection_method: ê°ì§€ ë°©ë²•
        market: ì‹œì¥ êµ¬ë¶„
        min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        count: ì¡°íšŒ ì¢…ëª© ìˆ˜
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "smart_money_signals": [
                {
                    "stock_code": "005930",
                    "stock_name": "ì‚¼ì„±ì „ì",
                    "signal_type": "INSTITUTIONAL_ACCUMULATION",
                    "confidence": 8.5,
                    "detection_details": {
                        "large_block_trades": 15,
                        "average_block_size": 345678900,
                        "institutional_buyers": ["ì—°ê¸°ê¸ˆ", "íˆ¬ì‹ ", "ì‚¬ëª¨í€ë“œ"],
                        "accumulation_period": "5D",
                        "price_impact": "MINIMAL"
                    },
                    "metrics": {
                        "net_buy_amount": 234567890000,
                        "avg_buy_price": 78200,
                        "current_price": 78500,
                        "unrealized_gain": 0.38,
                        "volume_weighted_price": 78350
                    },
                    "technical_context": {
                        "support_level": 77000,
                        "resistance_level": 80000,
                        "trend": "UPWARD",
                        "accumulation_zone": [77500, 78500]
                    },
                    "similar_patterns": [
                        {
                            "date": "2023-06-15",
                            "outcome": "20% gain in 30 days",
                            "similarity_score": 0.85
                        }
                    ]
                },
                ...
            ],
            "market_smart_money_index": {
                "current_value": 72.5,
                "trend": "INCREASING",
                "interpretation": "Smart money accumulating",
                "sector_focus": ["ë°˜ë„ì²´", "2ì°¨ì „ì§€", "ë°”ì´ì˜¤"],
                "risk_appetite": "MODERATE"
            },
            "institutional_positioning": {
                "net_exposure": "LONG",
                "leverage_estimate": 1.3,
                "sector_rotation": "TECHNOLOGY",
                "time_horizon": "MEDIUM_TERM"
            }
        }
    """
```

#### 7) `get_investor_sentiment`
```python
@tool
async def get_investor_sentiment(
    period: Literal["REAL_TIME", "1D", "1W", "1M"] = "1D",
    granularity: Literal["OVERALL", "BY_TYPE", "BY_SECTOR"] = "OVERALL"
) -> dict:
    """
    íˆ¬ìì ì‹¬ë¦¬ ì§€í‘œ ë¶„ì„
    
    Parameters:
        period: ë¶„ì„ ê¸°ê°„
        granularity: ë¶„ì„ ì„¸ë¶„í™” ìˆ˜ì¤€
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "sentiment_scores": {
                "overall": {
                    "score": 65.5,  # 0-100
                    "interpretation": "MODERATELY_BULLISH",
                    "change_from_yesterday": 3.2
                },
                "by_investor_type": {
                    "foreign": {
                        "score": 78.5,
                        "trend": "INCREASINGLY_BULLISH",
                        "key_drivers": ["tech_earnings", "weak_dollar"],
                        "consistency": 0.85
                    },
                    "institution": {
                        "score": 58.2,
                        "trend": "NEUTRAL",
                        "concerns": ["valuation", "interest_rates"],
                        "positioning": "DEFENSIVE"
                    },
                    "individual": {
                        "score": 45.3,
                        "trend": "CAUTIOUS",
                        "behavior": "PROFIT_TAKING",
                        "retail_favorites": ["ê²Œì„", "ì—”í„°", "ë°”ì´ì˜¤"]
                    }
                },
                "sentiment_drivers": {
                    "positive": [
                        {
                            "factor": "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì§€ì†",
                            "impact": 8.5,
                            "affected_sectors": ["ë°˜ë„ì²´", "ì „ê¸°ì „ì"]
                        }
                    ],
                    "negative": [
                        {
                            "factor": "ê¸°ê´€ ì°¨ìµì‹¤í˜„",
                            "impact": -5.2,
                            "affected_sectors": ["ê¸ˆìœµ", "ê±´ì„¤"]
                        }
                    ]
                },
                "divergence_indicators": {
                    "foreign_vs_domestic": 33.2,  # ê´´ë¦¬ë„
                    "institution_vs_individual": 12.9,
                    "interpretation": "ì™¸êµ­ì¸ ì£¼ë„ ì‹œì¥"
                }
            },
            "market_regime": {
                "current": "RISK_ON",
                "confidence": 0.72,
                "expected_duration": "2-4 weeks",
                "key_risks": ["ê¸ˆë¦¬ ì¸ìƒ", "ì¤‘êµ­ ê²½ê¸°"]
            },
            "actionable_insights": [
                {
                    "insight": "ì™¸êµ­ì¸ ë§¤ìˆ˜ì„¸ ê°•í•œ ëŒ€í˜• ê¸°ìˆ ì£¼ ì£¼ëª©",
                    "confidence": 8.0,
                    "timeframe": "SHORT_TERM"
                },
                {
                    "insight": "ê¸°ê´€ ìˆœë§¤ë„ ì—…ì¢… ë‹¨ê¸° ì¡°ì • ì˜ˆìƒ",
                    "confidence": 7.2,
                    "timeframe": "IMMEDIATE"
                }
            ]
        }
    """
```

## 4. ë¶„ì„ ì—”ì§„ êµ¬í˜„

### 4.1 íˆ¬ìì ë¶„ì„ ì—”ì§„

```python
# src/analysis/investor_analyzer.py
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class InvestorProfile:
    """íˆ¬ìì í”„ë¡œíŒŒì¼"""
    investor_type: str
    behavior_pattern: str
    risk_appetite: str
    typical_holding_period: int
    preferred_sectors: List[str]
    trading_style: str

class InvestorAnalyzer:
    """íˆ¬ìì í–‰ë™ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.profiles = self._initialize_profiles()
        self.behavior_models = {}
        
    def _initialize_profiles(self) -> Dict[str, InvestorProfile]:
        """íˆ¬ìì í”„ë¡œíŒŒì¼ ì´ˆê¸°í™”"""
        return {
            "FOREIGN": InvestorProfile(
                investor_type="FOREIGN",
                behavior_pattern="MOMENTUM",
                risk_appetite="MODERATE",
                typical_holding_period=90,
                preferred_sectors=["ê¸°ìˆ ", "ì†Œë¹„ì¬"],
                trading_style="TREND_FOLLOWING"
            ),
            "INSTITUTION": InvestorProfile(
                investor_type="INSTITUTION",
                behavior_pattern="VALUE",
                risk_appetite="LOW",
                typical_holding_period=180,
                preferred_sectors=["ê¸ˆìœµ", "ì‚°ì—…ì¬"],
                trading_style="CONTRARIAN"
            ),
            "INDIVIDUAL": InvestorProfile(
                investor_type="INDIVIDUAL",
                behavior_pattern="MIXED",
                risk_appetite="HIGH",
                typical_holding_period=30,
                preferred_sectors=["ë°”ì´ì˜¤", "ê²Œì„", "ì—”í„°"],
                trading_style="NOISE_TRADING"
            )
        }
    
    async def analyze_investor_behavior(
        self,
        trading_data: pd.DataFrame,
        investor_type: str
    ) -> Dict:
        """íˆ¬ìì í–‰ë™ íŒ¨í„´ ë¶„ì„"""
        
        profile = self.profiles.get(investor_type)
        
        analysis = {
            "investor_type": investor_type,
            "profile": profile,
            "behavior_metrics": self._calculate_behavior_metrics(trading_data, investor_type),
            "trading_patterns": self._identify_trading_patterns(trading_data, investor_type),
            "market_timing": self._analyze_market_timing(trading_data, investor_type),
            "sector_preference": self._analyze_sector_preference(trading_data, investor_type),
            "performance_analysis": self._analyze_performance(trading_data, investor_type)
        }
        
        # ì´ìƒ í–‰ë™ ê°ì§€
        analysis["anomalies"] = self._detect_anomalies(trading_data, investor_type)
        
        # ì˜ˆì¸¡ ëª¨ë¸
        analysis["predictions"] = await self._predict_future_behavior(analysis)
        
        return analysis
    
    def _calculate_behavior_metrics(
        self, 
        data: pd.DataFrame, 
        investor_type: str
    ) -> Dict:
        """í–‰ë™ ì§€í‘œ ê³„ì‚°"""
        
        net_trading = data[f'{investor_type.lower()}_net']
        
        return {
            "consistency_score": self._calculate_consistency(net_trading),
            "momentum_following": self._calculate_momentum_following(data, investor_type),
            "contrarian_score": self._calculate_contrarian_score(data, investor_type),
            "herding_index": self._calculate_herding_index(data, investor_type),
            "timing_skill": self._calculate_timing_skill(data, investor_type),
            "concentration_ratio": self._calculate_concentration(data, investor_type)
        }
    
    def _identify_trading_patterns(
        self,
        data: pd.DataFrame,
        investor_type: str
    ) -> List[Dict]:
        """ê±°ë˜ íŒ¨í„´ ì‹ë³„"""
        patterns = []
        
        # ëˆ„ì  ë§¤ìˆ˜/ë§¤ë„ íŒ¨í„´
        accumulation = self._detect_accumulation_pattern(data, investor_type)
        if accumulation:
            patterns.append(accumulation)
        
        # ë¶„ì‚° ë§¤ë„ íŒ¨í„´
        distribution = self._detect_distribution_pattern(data, investor_type)
        if distribution:
            patterns.append(distribution)
        
        # íšŒì „ ë§¤ë§¤ íŒ¨í„´
        rotation = self._detect_rotation_pattern(data, investor_type)
        if rotation:
            patterns.append(rotation)
        
        # íŒí•‘ íŒ¨í„´
        pumping = self._detect_pumping_pattern(data, investor_type)
        if pumping:
            patterns.append(pumping)
        
        return patterns
    
    def _detect_accumulation_pattern(
        self,
        data: pd.DataFrame,
        investor_type: str
    ) -> Optional[Dict]:
        """ëˆ„ì  ë§¤ìˆ˜ íŒ¨í„´ ê°ì§€"""
        
        net_buying = data[f'{investor_type.lower()}_net']
        prices = data['close']
        
        # ì—°ì† ìˆœë§¤ìˆ˜ ì¼ìˆ˜
        consecutive_buying = (net_buying > 0).astype(int)
        consecutive_count = consecutive_buying.groupby(
            (consecutive_buying != consecutive_buying.shift()).cumsum()
        ).cumsum()
        
        if consecutive_count.iloc[-1] >= 5:  # 5ì¼ ì´ìƒ ì—°ì† ë§¤ìˆ˜
            return {
                "pattern": "ACCUMULATION",
                "confidence": min(consecutive_count.iloc[-1] / 10, 1.0) * 100,
                "duration": consecutive_count.iloc[-1],
                "total_amount": net_buying.tail(consecutive_count.iloc[-1]).sum(),
                "average_price": prices.tail(consecutive_count.iloc[-1]).mean(),
                "price_trend": "UP" if prices.iloc[-1] > prices.iloc[-consecutive_count.iloc[-1]] else "DOWN"
            }
        
        return None
    
    def _analyze_market_timing(
        self,
        data: pd.DataFrame,
        investor_type: str
    ) -> Dict:
        """ì‹œì¥ íƒ€ì´ë° ë¶„ì„"""
        
        net_trading = data[f'{investor_type.lower()}_net']
        returns = data['returns']
        
        # ë§¤ìˆ˜/ë§¤ë„ í›„ ìˆ˜ìµë¥ 
        buy_timing = []
        sell_timing = []
        
        for i in range(len(data) - 20):
            if net_trading.iloc[i] > 0:  # ìˆœë§¤ìˆ˜
                future_return = returns.iloc[i:i+20].sum()
                buy_timing.append(future_return)
            elif net_trading.iloc[i] < 0:  # ìˆœë§¤ë„
                future_return = returns.iloc[i:i+20].sum()
                sell_timing.append(-future_return)  # ë§¤ë„ í›„ í•˜ë½ì´ ì¢‹ì€ íƒ€ì´ë°
        
        return {
            "buy_timing_score": np.mean(buy_timing) if buy_timing else 0,
            "sell_timing_score": np.mean(sell_timing) if sell_timing else 0,
            "overall_timing_skill": (np.mean(buy_timing) + np.mean(sell_timing)) / 2 if buy_timing and sell_timing else 0,
            "consistency": np.std(buy_timing + sell_timing) if buy_timing or sell_timing else float('inf'),
            "best_timing_examples": self._find_best_timing_examples(data, investor_type)
        }
```

### 4.2 ìê¸ˆ íë¦„ ë¶„ì„ê¸°

```python
# src/analysis/flow_analyzer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from scipy import stats

class FlowAnalyzer:
    """ìê¸ˆ íë¦„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.flow_cache = {}
        self.sector_mappings = self._load_sector_mappings()
        
    async def analyze_money_flow(
        self,
        market_data: pd.DataFrame,
        period: str = "1D"
    ) -> Dict:
        """ì‹œì¥ ì „ì²´ ìê¸ˆ íë¦„ ë¶„ì„"""
        
        flow_analysis = {
            "timestamp": datetime.now(),
            "period": period,
            "total_flow": self._calculate_total_flow(market_data),
            "flow_strength": self._calculate_flow_strength(market_data),
            "flow_persistence": self._calculate_flow_persistence(market_data),
            "sector_rotation": self._analyze_sector_rotation(market_data),
            "flow_concentration": self._calculate_flow_concentration(market_data),
            "smart_money_indicator": self._calculate_smart_money_indicator(market_data)
        }
        
        # ìê¸ˆ íë¦„ ì˜ˆì¸¡
        flow_analysis["flow_forecast"] = await self._forecast_flow(market_data)
        
        return flow_analysis
    
    def _calculate_flow_strength(self, data: pd.DataFrame) -> Dict:
        """ìê¸ˆ íë¦„ ê°•ë„ ê³„ì‚°"""
        
        foreign_flow = data['foreign_net'].sum()
        institution_flow = data['institution_net'].sum()
        individual_flow = data['individual_net'].sum()
        
        total_flow = abs(foreign_flow) + abs(institution_flow) + abs(individual_flow)
        
        return {
            "absolute_strength": total_flow,
            "directional_strength": foreign_flow + institution_flow,
            "foreign_dominance": abs(foreign_flow) / total_flow if total_flow > 0 else 0,
            "institution_dominance": abs(institution_flow) / total_flow if total_flow > 0 else 0,
            "flow_alignment": self._calculate_alignment(foreign_flow, institution_flow),
            "intensity_score": self._calculate_intensity_score(data)
        }
    
    def _analyze_sector_rotation(self, data: pd.DataFrame) -> Dict:
        """ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„"""
        
        sector_flows = {}
        
        for sector in self.sector_mappings:
            sector_data = data[data['sector'] == sector]
            if not sector_data.empty:
                sector_flows[sector] = {
                    "net_flow": sector_data['foreign_net'].sum() + sector_data['institution_net'].sum(),
                    "foreign_flow": sector_data['foreign_net'].sum(),
                    "institution_flow": sector_data['institution_net'].sum(),
                    "momentum": self._calculate_sector_momentum(sector_data),
                    "relative_strength": self._calculate_relative_strength(sector_data, data)
                }
        
        # ë¡œí…Œì´ì…˜ ë§¤íŠ¸ë¦­ìŠ¤
        rotation_matrix = self._build_rotation_matrix(sector_flows)
        
        return {
            "sector_flows": sector_flows,
            "rotation_matrix": rotation_matrix,
            "from_sectors": self._identify_outflow_sectors(sector_flows),
            "to_sectors": self._identify_inflow_sectors(sector_flows),
            "rotation_intensity": self._calculate_rotation_intensity(sector_flows),
            "cycle_phase": self._identify_cycle_phase(rotation_matrix)
        }
    
    def _calculate_smart_money_indicator(self, data: pd.DataFrame) -> Dict:
        """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì§€í‘œ ê³„ì‚°"""
        
        # ëŒ€ëŸ‰ ê±°ë˜ ê°ì§€
        large_trades = self._detect_large_trades(data)
        
        # ê¸°ê´€/ì™¸êµ­ì¸ ë™ì¡°í™”
        synchronization = self._calculate_synchronization(data)
        
        # ê°€ê²© ì˜í–¥ ìµœì†Œí™” ê±°ë˜
        stealth_accumulation = self._detect_stealth_accumulation(data)
        
        # ì¢…í•© ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì ìˆ˜
        smart_money_score = (
            large_trades['score'] * 0.3 +
            synchronization['score'] * 0.4 +
            stealth_accumulation['score'] * 0.3
        )
        
        return {
            "score": smart_money_score,
            "components": {
                "large_trades": large_trades,
                "synchronization": synchronization,
                "stealth_accumulation": stealth_accumulation
            },
            "interpretation": self._interpret_smart_money_score(smart_money_score),
            "confidence": self._calculate_confidence(data),
            "recent_signals": self._get_recent_smart_money_signals(data)
        }
```

### 4.3 íŒ¨í„´ ê°ì§€ê¸°

```python
# src/analysis/pattern_detector.py
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import numpy as np

class InvestorPatternDetector:
    """íˆ¬ìì íŒ¨í„´ ê°ì§€ê¸°"""
    
    def __init__(self):
        self.pattern_library = self._build_pattern_library()
        self.ml_models = {}
        
    def detect_patterns(
        self,
        investor_data: pd.DataFrame,
        min_confidence: float = 0.7
    ) -> List[Dict]:
        """íˆ¬ìì íŒ¨í„´ ê°ì§€"""
        
        detected_patterns = []
        
        # ê¸°ë³¸ íŒ¨í„´ ê°ì§€
        for pattern_name, pattern_func in self.pattern_library.items():
            result = pattern_func(investor_data)
            if result and result['confidence'] >= min_confidence:
                detected_patterns.append(result)
        
        # ML ê¸°ë°˜ ì´ìƒ íŒ¨í„´ ê°ì§€
        anomaly_patterns = self._detect_anomaly_patterns(investor_data)
        detected_patterns.extend(anomaly_patterns)
        
        # íŒ¨í„´ ì¡°í•© ë¶„ì„
        combined_patterns = self._analyze_pattern_combinations(detected_patterns)
        
        return {
            "individual_patterns": detected_patterns,
            "combined_patterns": combined_patterns,
            "pattern_strength": self._calculate_pattern_strength(detected_patterns),
            "market_implications": self._analyze_implications(detected_patterns)
        }
    
    def _build_pattern_library(self) -> Dict:
        """íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•"""
        return {
            "accumulation": self._detect_accumulation,
            "distribution": self._detect_distribution,
            "pump_and_dump": self._detect_pump_and_dump,
            "stop_hunting": self._detect_stop_hunting,
            "window_dressing": self._detect_window_dressing,
            "front_running": self._detect_front_running,
            "iceberg_orders": self._detect_iceberg_orders
        }
    
    def _detect_pump_and_dump(self, data: pd.DataFrame) -> Optional[Dict]:
        """íŒí”„ ì•¤ ë¤í”„ íŒ¨í„´ ê°ì§€"""
        
        # ë‹¨ê¸°ê°„ ê¸‰ë“± í›„ ëŒ€ëŸ‰ ë§¤ë„
        price_surge = data['close'].pct_change(5).iloc[-1]  # 5ì¼ ìˆ˜ìµë¥ 
        recent_volume = data['volume'].iloc[-5:].mean()
        avg_volume = data['volume'].iloc[-30:-5].mean()
        
        # ì™¸êµ­ì¸/ê¸°ê´€ ë§¤ë„ í™•ì¸
        recent_institutional_flow = data['institution_net'].iloc[-3:].sum()
        recent_foreign_flow = data['foreign_net'].iloc[-3:].sum()
        
        if (price_surge > 0.3 and  # 30% ì´ìƒ ê¸‰ë“±
            recent_volume > avg_volume * 3 and  # ê±°ë˜ëŸ‰ 3ë°° ì´ìƒ
            recent_institutional_flow < 0 and  # ê¸°ê´€ ë§¤ë„
            recent_foreign_flow < 0):  # ì™¸êµ­ì¸ ë§¤ë„
            
            return {
                "pattern": "PUMP_AND_DUMP",
                "confidence": 0.85,
                "stage": "DUMP",
                "price_surge": price_surge,
                "volume_spike": recent_volume / avg_volume,
                "institutional_selling": abs(recent_institutional_flow),
                "risk_level": "EXTREME",
                "recommended_action": "AVOID"
            }
        
        return None
    
    def _detect_anomaly_patterns(self, data: pd.DataFrame) -> List[Dict]:
        """ML ê¸°ë°˜ ì´ìƒ íŒ¨í„´ ê°ì§€"""
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self._extract_features(data)
        
        # ì •ê·œí™”
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        # DBSCAN í´ëŸ¬ìŠ¤í„°ë§
        clustering = DBSCAN(eps=0.5, min_samples=5)
        labels = clustering.fit_predict(features_scaled)
        
        # ì´ìƒì¹˜ ì‹ë³„ (ë¼ë²¨ -1)
        anomalies = []
        anomaly_indices = np.where(labels == -1)[0]
        
        for idx in anomaly_indices:
            anomaly = self._analyze_anomaly(data.iloc[idx], features[idx])
            if anomaly:
                anomalies.append(anomaly)
        
        return anomalies
```

### 4.4 ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì ê¸°

```python
# src/analysis/smart_money.py
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np

class SmartMoneyTracker:
    """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì  ë° ë¶„ì„"""
    
    def __init__(self):
        self.smart_money_criteria = {
            "large_order_threshold": 1000000000,  # 10ì–µì›
            "institution_types": ["ì—°ê¸°ê¸ˆ", "ìì‚°ìš´ìš©", "ë³´í—˜", "ì€í–‰"],
            "foreign_quality_threshold": 0.7
        }
        
    async def track_smart_money(
        self,
        market_data: pd.DataFrame,
        transaction_data: pd.DataFrame
    ) -> Dict:
        """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì """
        
        # ëŒ€í˜• ë¸”ë¡ ê±°ë˜ ì‹ë³„
        block_trades = self._identify_block_trades(transaction_data)
        
        # ê¸°ê´€ íˆ¬ìì í’ˆì§ˆ í‰ê°€
        institutional_quality = self._assess_institutional_quality(transaction_data)
        
        # ì™¸êµ­ì¸ íˆ¬ìì ë¶„ë¥˜
        foreign_classification = self._classify_foreign_investors(transaction_data)
        
        # ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ íë¦„ ê³„ì‚°
        smart_money_flow = self._calculate_smart_money_flow(
            block_trades,
            institutional_quality,
            foreign_classification
        )
        
        # ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ íƒ€ê²Ÿ ì¢…ëª©
        target_stocks = self._identify_target_stocks(smart_money_flow)
        
        return {
            "timestamp": datetime.now(),
            "smart_money_flow": smart_money_flow,
            "target_stocks": target_stocks,
            "market_positioning": self._analyze_positioning(smart_money_flow),
            "sector_preferences": self._analyze_sector_preferences(smart_money_flow),
            "timing_analysis": self._analyze_timing(smart_money_flow),
            "follow_recommendations": self._generate_recommendations(target_stocks)
        }
    
    def _identify_block_trades(self, data: pd.DataFrame) -> List[Dict]:
        """ë¸”ë¡ ê±°ë˜ ì‹ë³„"""
        
        block_trades = []
        
        for _, trade in data.iterrows():
            if trade['amount'] >= self.smart_money_criteria['large_order_threshold']:
                block_trade = {
                    "timestamp": trade['timestamp'],
                    "stock_code": trade['stock_code'],
                    "amount": trade['amount'],
                    "price": trade['price'],
                    "investor_type": trade['investor_type'],
                    "execution_quality": self._assess_execution_quality(trade),
                    "market_impact": self._calculate_market_impact(trade),
                    "stealth_score": self._calculate_stealth_score(trade)
                }
                block_trades.append(block_trade)
        
        return block_trades
    
    def _assess_institutional_quality(self, data: pd.DataFrame) -> Dict:
        """ê¸°ê´€ íˆ¬ìì í’ˆì§ˆ í‰ê°€"""
        
        quality_scores = {}
        
        for inst_type in self.smart_money_criteria['institution_types']:
            inst_data = data[data['institution_subtype'] == inst_type]
            
            if not inst_data.empty:
                quality_scores[inst_type] = {
                    "historical_performance": self._calculate_historical_performance(inst_data),
                    "timing_skill": self._calculate_timing_skill(inst_data),
                    "selection_skill": self._calculate_selection_skill(inst_data),
                    "consistency": self._calculate_consistency(inst_data),
                    "information_ratio": self._calculate_information_ratio(inst_data)
                }
        
        return quality_scores
    
    def _calculate_smart_money_flow(
        self,
        block_trades: List[Dict],
        institutional_quality: Dict,
        foreign_classification: Dict
    ) -> Dict:
        """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ìê¸ˆ íë¦„ ê³„ì‚°"""
        
        smart_flow = {
            "total_inflow": 0,
            "total_outflow": 0,
            "net_flow": 0,
            "by_investor_type": {},
            "by_stock": {},
            "quality_weighted_flow": 0
        }
        
        # ë¸”ë¡ ê±°ë˜ ê¸°ë°˜ íë¦„
        for trade in block_trades:
            amount = trade['amount'] if trade['amount'] > 0 else 0
            
            # í’ˆì§ˆ ê°€ì¤‘ì¹˜ ì ìš©
            quality_weight = self._get_quality_weight(
                trade['investor_type'],
                institutional_quality,
                foreign_classification
            )
            
            weighted_amount = amount * quality_weight
            
            if trade['amount'] > 0:
                smart_flow['total_inflow'] += weighted_amount
            else:
                smart_flow['total_outflow'] += abs(weighted_amount)
            
            # ì¢…ëª©ë³„ ì§‘ê³„
            stock_code = trade['stock_code']
            if stock_code not in smart_flow['by_stock']:
                smart_flow['by_stock'][stock_code] = {
                    'inflow': 0,
                    'outflow': 0,
                    'net': 0,
                    'trades': []
                }
            
            smart_flow['by_stock'][stock_code]['trades'].append(trade)
            
        smart_flow['net_flow'] = smart_flow['total_inflow'] - smart_flow['total_outflow']
        
        return smart_flow
```

## 5. ìºì‹± ë° ì„±ëŠ¥ ìµœì í™”

```python
# src/utils/cache.py
from typing import Dict, Any, Optional
import asyncio
from datetime import datetime, timedelta
import redis
import json

class InvestorDataCache:
    """íˆ¬ìì ë°ì´í„° ì „ìš© ìºì‹œ"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.memory_cache = {}
        self.cache_ttl = {
            "real_time": 10,  # 10ì´ˆ
            "minute": 60,
            "hourly": 3600,
            "daily": 86400
        }
        
    async def get_investor_data(
        self,
        key: str,
        fetch_func,
        data_type: str = "minute"
    ) -> Any:
        """íˆ¬ìì ë°ì´í„° ìºì‹œ ì¡°íšŒ"""
        
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if key in self.memory_cache:
            entry = self.memory_cache[key]
            if entry['expires'] > datetime.now():
                return entry['data']
        
        # 2. Redis ìºì‹œ í™•ì¸
        redis_data = await self._get_from_redis(key)
        if redis_data:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
            self.memory_cache[key] = {
                'data': redis_data,
                'expires': datetime.now() + timedelta(seconds=self.cache_ttl[data_type])
            }
            return redis_data
        
        # 3. ë°ì´í„° fetch
        data = await fetch_func()
        
        # 4. ìºì‹œ ì €ì¥
        await self._save_to_cache(key, data, data_type)
        
        return data
    
    async def _get_from_redis(self, key: str) -> Optional[Any]:
        """Redisì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        try:
            data = self.redis.get(key)
            if data:
                return json.loads(data)
        except Exception as e:
            print(f"Redis get error: {e}")
        return None
    
    async def _save_to_cache(self, key: str, data: Any, data_type: str):
        """ìºì‹œì— ì €ì¥"""
        ttl = self.cache_ttl[data_type]
        
        # Redis ì €ì¥
        try:
            self.redis.setex(key, ttl, json.dumps(data))
        except Exception as e:
            print(f"Redis set error: {e}")
        
        # ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥
        self.memory_cache[key] = {
            'data': data,
            'expires': datetime.now() + timedelta(seconds=ttl)
        }
        
        # ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸° ê´€ë¦¬
        if len(self.memory_cache) > 1000:
            self._evict_old_entries()
    
    def _evict_old_entries(self):
        """ì˜¤ë˜ëœ ìºì‹œ í•­ëª© ì œê±°"""
        current_time = datetime.now()
        keys_to_remove = [
            k for k, v in self.memory_cache.items()
            if v['expires'] < current_time
        ]
        for key in keys_to_remove:
            del self.memory_cache[key]
```

## 6. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
-- PostgreSQL + TimescaleDB ìŠ¤í‚¤ë§ˆ

-- íˆ¬ìì ê±°ë˜ í…Œì´ë¸”
CREATE TABLE investor_trading (
    timestamp TIMESTAMPTZ NOT NULL,
    stock_code VARCHAR(10) NOT NULL,
    foreign_buy BIGINT,
    foreign_sell BIGINT,
    foreign_net BIGINT,
    institution_buy BIGINT,
    institution_sell BIGINT,
    institution_net BIGINT,
    individual_buy BIGINT,
    individual_sell BIGINT,
    individual_net BIGINT,
    program_buy BIGINT,
    program_sell BIGINT,
    program_net BIGINT,
    PRIMARY KEY (timestamp, stock_code)
);

-- TimescaleDB í•˜ì´í¼í…Œì´ë¸” ë³€í™˜
SELECT create_hypertable('investor_trading', 'timestamp');

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_investor_trading_stock ON investor_trading (stock_code, timestamp DESC);
CREATE INDEX idx_investor_trading_foreign_net ON investor_trading (foreign_net);
CREATE INDEX idx_investor_trading_institution_net ON investor_trading (institution_net);

-- ê¸°ê´€ íˆ¬ìì ì„¸ë¶€ í…Œì´ë¸”
CREATE TABLE institution_detail (
    timestamp TIMESTAMPTZ NOT NULL,
    stock_code VARCHAR(10) NOT NULL,
    institution_type VARCHAR(50) NOT NULL,
    buy_amount BIGINT,
    sell_amount BIGINT,
    net_amount BIGINT,
    PRIMARY KEY (timestamp, stock_code, institution_type)
);

SELECT create_hypertable('institution_detail', 'timestamp');

-- í”„ë¡œê·¸ë¨ ë§¤ë§¤ ìƒì„¸ í…Œì´ë¸”
CREATE TABLE program_trading_detail (
    timestamp TIMESTAMPTZ NOT NULL,
    stock_code VARCHAR(10),
    program_type VARCHAR(20) NOT NULL, -- ARBITRAGE, NON_ARBITRAGE
    buy_amount BIGINT,
    sell_amount BIGINT,
    net_amount BIGINT,
    PRIMARY KEY (timestamp, stock_code, program_type)
);

SELECT create_hypertable('program_trading_detail', 'timestamp');

-- ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì  í…Œì´ë¸”
CREATE TABLE smart_money_signals (
    signal_id SERIAL PRIMARY KEY,
    timestamp TIMESTAMPTZ NOT NULL,
    stock_code VARCHAR(10) NOT NULL,
    signal_type VARCHAR(50),
    confidence FLOAT,
    amount BIGINT,
    investor_type VARCHAR(20),
    metadata JSONB
);

CREATE INDEX idx_smart_money_timestamp ON smart_money_signals (timestamp DESC);
CREATE INDEX idx_smart_money_stock ON smart_money_signals (stock_code);
CREATE INDEX idx_smart_money_confidence ON smart_money_signals (confidence DESC);
```

## 7. êµ¬í˜„ ì¼ì •

### Phase 1: ê¸°ì´ˆ êµ¬í˜„ (4ì¼)
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •
- [ ] MCP ì„œë²„ ê¸°ë³¸ êµ¬í˜„
- [ ] API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ (í•œíˆ¬, ì´ë² ìŠ¤íŠ¸)
- [ ] ê¸°ë³¸ íˆ¬ìì ë™í–¥ ë„êµ¬ êµ¬í˜„

### Phase 2: í•µì‹¬ ê¸°ëŠ¥ (6ì¼)
- [ ] 7ê°œ ì£¼ìš” ë„êµ¬ êµ¬í˜„
- [ ] íˆ¬ìì ë¶„ì„ ì—”ì§„ êµ¬í˜„
- [ ] ìê¸ˆ íë¦„ ë¶„ì„ê¸° êµ¬í˜„
- [ ] íŒ¨í„´ ê°ì§€ê¸° êµ¬í˜„

### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ (5ì¼)
- [ ] ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì ê¸° êµ¬í˜„
- [ ] ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
- [ ] ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„

### Phase 4: í†µí•© ë° í…ŒìŠ¤íŠ¸ (3ì¼)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ìµœì í™”
- [ ] ë¬¸ì„œí™”
- [ ] ë°°í¬ ì¤€ë¹„

## 8. í…ŒìŠ¤íŠ¸ ê³„íš

### 8.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_analyzer.py
import pytest
import pandas as pd
import numpy as np
from src.analysis.investor_analyzer import InvestorAnalyzer
from src.analysis.smart_money import SmartMoneyTracker

class TestInvestorAnalyzer:
    @pytest.fixture
    def sample_trading_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ê±°ë˜ ë°ì´í„°"""
        dates = pd.date_range('2024-01-01', periods=30, freq='D')
        return pd.DataFrame({
            'timestamp': dates,
            'foreign_buy': np.random.uniform(1e9, 1e10, 30),
            'foreign_sell': np.random.uniform(1e9, 1e10, 30),
            'institution_buy': np.random.uniform(5e8, 5e9, 30),
            'institution_sell': np.random.uniform(5e8, 5e9, 30),
            'individual_buy': np.random.uniform(1e9, 2e9, 30),
            'individual_sell': np.random.uniform(1e9, 2e9, 30),
            'close': np.random.uniform(50000, 60000, 30)
        })
    
    @pytest.mark.asyncio
    async def test_behavior_analysis(self, sample_trading_data):
        """íˆ¬ìì í–‰ë™ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        analyzer = InvestorAnalyzer()
        
        # ì™¸êµ­ì¸ íˆ¬ìì ë¶„ì„
        result = await analyzer.analyze_investor_behavior(
            sample_trading_data,
            "FOREIGN"
        )
        
        assert 'behavior_metrics' in result
        assert 'trading_patterns' in result
        assert 'market_timing' in result
        assert result['behavior_metrics']['consistency_score'] >= 0
        
    @pytest.mark.asyncio
    async def test_pattern_detection(self, sample_trading_data):
        """íŒ¨í„´ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        analyzer = InvestorAnalyzer()
        
        # ì—°ì† ë§¤ìˆ˜ íŒ¨í„´ ìƒì„±
        sample_trading_data['foreign_net'] = 1000000000  # 10ì–µ ìˆœë§¤ìˆ˜
        
        result = await analyzer.analyze_investor_behavior(
            sample_trading_data,
            "FOREIGN"
        )
        
        patterns = result['trading_patterns']
        assert any(p['pattern'] == 'ACCUMULATION' for p in patterns)

@pytest.mark.asyncio
async def test_smart_money_tracking():
    """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì¶”ì  í…ŒìŠ¤íŠ¸"""
    tracker = SmartMoneyTracker()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    market_data = pd.DataFrame({
        'stock_code': ['005930'] * 10,
        'close': np.linspace(70000, 75000, 10),
        'volume': np.random.uniform(1e7, 2e7, 10)
    })
    
    transaction_data = pd.DataFrame({
        'timestamp': pd.date_range('2024-01-01', periods=10, freq='H'),
        'stock_code': '005930',
        'amount': [2e9, -5e8, 3e9, -1e9, 5e9, -2e9, 4e9, -3e9, 6e9, -1e9],
        'price': np.linspace(70000, 75000, 10),
        'investor_type': ['FOREIGN'] * 5 + ['INSTITUTION'] * 5,
        'institution_subtype': [None] * 5 + ['ì—°ê¸°ê¸ˆ'] * 5
    })
    
    result = await tracker.track_smart_money(market_data, transaction_data)
    
    assert 'smart_money_flow' in result
    assert 'target_stocks' in result
    assert result['smart_money_flow']['net_flow'] != 0
```

### 8.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/test_integration.py
import pytest
from src.server import InvestorTrendsMCPServer

@pytest.mark.asyncio
async def test_investor_trading_flow():
    """íˆ¬ìì ê±°ë˜ ì¡°íšŒ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    server = InvestorTrendsMCPServer()
    
    # ì‹œì¥ ì „ì²´ íˆ¬ìì ë™í–¥
    result = await server.get_investor_trading(
        investor_type="ALL",
        period="1D",
        market="KOSPI"
    )
    
    assert 'investor_data' in result
    assert 'foreign' in result['investor_data']
    assert 'institution' in result['investor_data']
    assert 'individual' in result['investor_data']
    
    # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
    foreign_net = result['investor_data']['foreign']['net_amount']
    institution_net = result['investor_data']['institution']['net_amount']
    individual_net = result['investor_data']['individual']['net_amount']
    
    # ì‹œì¥ ì „ì²´ì˜ ìˆœë§¤ìˆ˜ í•©ì€ 0ì´ì–´ì•¼ í•¨
    assert abs(foreign_net + institution_net + individual_net) < 1000000  # ì˜¤ì°¨ í—ˆìš©

@pytest.mark.asyncio
async def test_smart_money_detection():
    """ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    server = InvestorTrendsMCPServer()
    
    result = await server.get_smart_money_tracker(
        detection_method="INSTITUTION_CLUSTER",
        market="KOSPI",
        min_confidence=7.0
    )
    
    assert 'smart_money_signals' in result
    assert all(signal['confidence'] >= 7.0 for signal in result['smart_money_signals'])
```

## 9. ë°°í¬ ë° ìš´ì˜

### 9.1 í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼
KOREA_INVESTMENT_APP_KEY=your_app_key
KOREA_INVESTMENT_APP_SECRET=your_app_secret
EBEST_APP_KEY=your_ebest_key
EBEST_APP_SECRET=your_ebest_secret
DATABASE_URL=postgresql://user:pass@localhost:5432/investor_trends
REDIS_URL=redis://localhost:6379
LOG_LEVEL=INFO
CACHE_TTL_REALTIME=10
CACHE_TTL_MINUTE=60
SMART_MONEY_THRESHOLD=1000000000
```

### 9.2 Docker ì„¤ì •

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# ì‹¤í–‰
CMD ["python", "-m", "src.server"]
```

### 9.3 Docker Compose ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  mcp-investor-trends:
    build: .
    container_name: mcp-investor-trends
    environment:
      - KOREA_INVESTMENT_APP_KEY=${KOREA_INVESTMENT_APP_KEY}
      - KOREA_INVESTMENT_APP_SECRET=${KOREA_INVESTMENT_APP_SECRET}
      - EBEST_APP_KEY=${EBEST_APP_KEY}
      - EBEST_APP_SECRET=${EBEST_APP_SECRET}
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/investor_trends
      - REDIS_URL=redis://redis:6379
    ports:
      - "8083:8080"
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      
  postgres:
    image: timescale/timescaledb:latest-pg14
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=investor_trends
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

volumes:
  postgres_data:
  redis_data:
```

## 10. ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜

### 10.1 ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
# src/utils/monitoring.py
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional
import asyncio
import psutil

@dataclass
class SystemMetrics:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­"""
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    active_connections: int
    cache_hit_rate: float
    db_query_time: float
    api_response_time: float

class InvestorMonitor:
    """íˆ¬ìì ë™í–¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics_buffer = []
        self.alert_thresholds = {
            "flow_anomaly": 3.0,  # í‘œì¤€í¸ì°¨
            "api_latency": 2000,  # ms
            "cache_hit_rate": 0.6,
            "error_rate": 0.05
        }
        
    async def monitor_system_health(self) -> Dict:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§"""
        
        metrics = SystemMetrics(
            timestamp=datetime.now(),
            cpu_usage=psutil.cpu_percent(),
            memory_usage=psutil.virtual_memory().percent,
            active_connections=await self._count_active_connections(),
            cache_hit_rate=await self._get_cache_hit_rate(),
            db_query_time=await self._measure_db_query_time(),
            api_response_time=await self._measure_api_response_time()
        )
        
        self.metrics_buffer.append(metrics)
        
        # ì´ìƒ ê°ì§€
        anomalies = self._detect_anomalies(metrics)
        
        return {
            "current_metrics": metrics,
            "anomalies": anomalies,
            "health_score": self._calculate_health_score(metrics),
            "recommendations": self._generate_recommendations(metrics, anomalies)
        }
    
    async def monitor_investor_flows(self) -> Dict:
        """íˆ¬ìì ìê¸ˆ íë¦„ ëª¨ë‹ˆí„°ë§"""
        
        # ì‹¤ì‹œê°„ ìê¸ˆ íë¦„
        current_flows = await self._get_current_flows()
        
        # ì´ìƒ ê±°ë˜ ê°ì§€
        anomalous_flows = self._detect_flow_anomalies(current_flows)
        
        # íŒ¨í„´ ë³€í™” ê°ì§€
        pattern_changes = self._detect_pattern_changes(current_flows)
        
        return {
            "timestamp": datetime.now(),
            "current_flows": current_flows,
            "anomalous_flows": anomalous_flows,
            "pattern_changes": pattern_changes,
            "market_sentiment": self._calculate_market_sentiment(current_flows),
            "risk_indicators": self._calculate_risk_indicators(current_flows)
        }
    
    def _detect_flow_anomalies(self, flows: Dict) -> List[Dict]:
        """ìê¸ˆ íë¦„ ì´ìƒ ê°ì§€"""
        anomalies = []
        
        for investor_type, flow_data in flows.items():
            # Z-score ê³„ì‚°
            z_score = self._calculate_z_score(flow_data['net_amount'])
            
            if abs(z_score) > self.alert_thresholds['flow_anomaly']:
                anomalies.append({
                    "investor_type": investor_type,
                    "net_amount": flow_data['net_amount'],
                    "z_score": z_score,
                    "severity": "HIGH" if abs(z_score) > 4 else "MEDIUM",
                    "possible_causes": self._analyze_anomaly_causes(investor_type, flow_data)
                })
        
        return anomalies
    
    async def generate_daily_report(self) -> Dict:
        """ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # ì¼ì¼ í†µê³„
        daily_stats = await self._calculate_daily_statistics()
        
        # ì£¼ìš” ì´ë²¤íŠ¸
        key_events = await self._identify_key_events()
        
        # íˆ¬ììë³„ ì„±ê³¼
        investor_performance = await self._analyze_investor_performance()
        
        # ì‹œì¥ ì „ë§
        market_outlook = await self._generate_market_outlook()
        
        return {
            "report_date": datetime.now().date(),
            "executive_summary": self._generate_executive_summary(daily_stats),
            "daily_statistics": daily_stats,
            "key_events": key_events,
            "investor_performance": investor_performance,
            "market_outlook": market_outlook,
            "action_items": self._generate_action_items(daily_stats, key_events)
        }
```

### 10.2 ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ

```python
# src/utils/log_analyzer.py
import re
from collections import defaultdict, Counter
from datetime import datetime, timedelta
import json

class InvestorLogAnalyzer:
    """íˆ¬ìì ë™í–¥ ë¡œê·¸ ë¶„ì„"""
    
    def __init__(self):
        self.patterns = {
            "large_transaction": re.compile(r"LARGE_TRANSACTION.*amount:(\d+).*investor:(\w+)"),
            "anomaly_detected": re.compile(r"ANOMALY.*type:(\w+).*severity:(\w+)"),
            "api_error": re.compile(r"API_ERROR.*endpoint:(\w+).*code:(\d+)"),
            "smart_money": re.compile(r"SMART_MONEY.*stock:(\w+).*confidence:([\d.]+)")
        }
        
    def analyze_logs(self, log_file: str, time_window: timedelta) -> Dict:
        """ë¡œê·¸ ë¶„ì„"""
        
        analysis_result = {
            "time_window": time_window,
            "transaction_analysis": defaultdict(list),
            "anomaly_summary": defaultdict(int),
            "api_health": defaultdict(lambda: {"success": 0, "error": 0}),
            "smart_money_signals": [],
            "performance_metrics": {}
        }
        
        with open(log_file, 'r') as f:
            for line in f:
                self._process_log_line(line, analysis_result)
        
        # ì§‘ê³„ ë° ìš”ì•½
        analysis_result["summary"] = self._generate_summary(analysis_result)
        
        return analysis_result
    
    def _process_log_line(self, line: str, result: Dict):
        """ê°œë³„ ë¡œê·¸ ë¼ì¸ ì²˜ë¦¬"""
        
        # ëŒ€í˜• ê±°ë˜ ê°ì§€
        large_tx_match = self.patterns["large_transaction"].search(line)
        if large_tx_match:
            amount, investor = large_tx_match.groups()
            result["transaction_analysis"][investor].append({
                "amount": int(amount),
                "timestamp": self._extract_timestamp(line)
            })
        
        # ì´ìƒ ê±°ë˜ ê°ì§€
        anomaly_match = self.patterns["anomaly_detected"].search(line)
        if anomaly_match:
            anomaly_type, severity = anomaly_match.groups()
            result["anomaly_summary"][f"{anomaly_type}_{severity}"] += 1
        
        # API ìƒíƒœ
        api_match = self.patterns["api_error"].search(line)
        if api_match:
            endpoint, code = api_match.groups()
            if int(code) >= 400:
                result["api_health"][endpoint]["error"] += 1
            else:
                result["api_health"][endpoint]["success"] += 1
        
        # ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì‹ í˜¸
        smart_match = self.patterns["smart_money"].search(line)
        if smart_match:
            stock, confidence = smart_match.groups()
            result["smart_money_signals"].append({
                "stock": stock,
                "confidence": float(confidence),
                "timestamp": self._extract_timestamp(line)
            })
    
    def generate_insights(self, analysis_result: Dict) -> List[Dict]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
        
        insights = []
        
        # íˆ¬ììë³„ í–‰ë™ íŒ¨í„´
        for investor, transactions in analysis_result["transaction_analysis"].items():
            if len(transactions) >= 10:
                insights.append({
                    "type": "HIGH_ACTIVITY",
                    "investor": investor,
                    "transaction_count": len(transactions),
                    "total_amount": sum(tx["amount"] for tx in transactions),
                    "interpretation": f"{investor} íˆ¬ììì˜ í™œë°œí•œ ê±°ë˜ ê°ì§€"
                })
        
        # ì´ìƒ ê±°ë˜ íŒ¨í„´
        for anomaly_type, count in analysis_result["anomaly_summary"].items():
            if count > 5:
                insights.append({
                    "type": "FREQUENT_ANOMALY",
                    "anomaly_type": anomaly_type,
                    "count": count,
                    "interpretation": f"{anomaly_type} ìœ í˜•ì˜ ì´ìƒ ê±°ë˜ ë¹ˆë°œ"
                })
        
        # ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì›€ì§ì„
        high_confidence_signals = [
            s for s in analysis_result["smart_money_signals"] 
            if s["confidence"] > 8.0
        ]
        if high_confidence_signals:
            insights.append({
                "type": "SMART_MONEY_ACTIVITY",
                "signal_count": len(high_confidence_signals),
                "top_stocks": Counter(s["stock"] for s in high_confidence_signals).most_common(5),
                "interpretation": "ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆì˜ ì§‘ì¤‘ ë§¤ìˆ˜ ì‹ í˜¸ í¬ì°©"
            })
        
        return insights
```

### 10.3 ì•Œë¦¼ ì‹œìŠ¤í…œ

```python
# src/utils/alerting.py
from typing import Dict, List
import asyncio
from enum import Enum

class AlertLevel(Enum):
    INFO = "INFO"
    WARNING = "WARNING"
    CRITICAL = "CRITICAL"

class InvestorAlertSystem:
    """íˆ¬ìì ë™í–¥ ì•Œë¦¼ ì‹œìŠ¤í…œ"""
    
    def __init__(self, webhook_url: str = None):
        self.webhook_url = webhook_url
        self.alert_rules = self._initialize_alert_rules()
        self.alert_history = []
        
    def _initialize_alert_rules(self) -> Dict:
        """ì•Œë¦¼ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            "massive_foreign_selling": {
                "condition": lambda data: data.get("foreign_net", 0) < -100000000000,  # -1000ì–µ
                "level": AlertLevel.CRITICAL,
                "message": "ì™¸êµ­ì¸ ëŒ€ê·œëª¨ ìˆœë§¤ë„ ê°ì§€: {amount}ì–µì›"
            },
            "institution_accumulation": {
                "condition": lambda data: data.get("institution_net", 0) > 50000000000,  # 500ì–µ
                "level": AlertLevel.WARNING,
                "message": "ê¸°ê´€ ëŒ€ê·œëª¨ ìˆœë§¤ìˆ˜ ê°ì§€: {amount}ì–µì›"
            },
            "smart_money_signal": {
                "condition": lambda data: data.get("smart_money_confidence", 0) > 8.5,
                "level": AlertLevel.INFO,
                "message": "ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì‹ í˜¸ ê°ì§€: {stock} (ì‹ ë¢°ë„: {confidence})"
            },
            "flow_reversal": {
                "condition": lambda data: data.get("flow_reversal", False),
                "level": AlertLevel.WARNING,
                "message": "íˆ¬ìì ë§¤ë§¤ ë°©í–¥ ì „í™˜ ê°ì§€: {investor_type}"
            }
        }
    
    async def check_alerts(self, market_data: Dict) -> List[Dict]:
        """ì•Œë¦¼ ì¡°ê±´ ì²´í¬"""
        triggered_alerts = []
        
        for rule_name, rule in self.alert_rules.items():
            if rule["condition"](market_data):
                alert = {
                    "timestamp": datetime.now(),
                    "rule": rule_name,
                    "level": rule["level"],
                    "message": self._format_message(rule["message"], market_data),
                    "data": market_data
                }
                
                triggered_alerts.append(alert)
                await self._send_alert(alert)
        
        # ì•Œë¦¼ ì´ë ¥ ì €ì¥
        self.alert_history.extend(triggered_alerts)
        
        return triggered_alerts
    
    async def _send_alert(self, alert: Dict):
        """ì•Œë¦¼ ì „ì†¡"""
        if alert["level"] == AlertLevel.CRITICAL:
            # ê¸´ê¸‰ ì•Œë¦¼ (SMS, ì „í™” ë“±)
            await self._send_critical_alert(alert)
        elif alert["level"] == AlertLevel.WARNING:
            # ê²½ê³  ì•Œë¦¼ (ì´ë©”ì¼, Slack ë“±)
            await self._send_warning_alert(alert)
        else:
            # ì •ë³´ì„± ì•Œë¦¼ (ë¡œê·¸, ëŒ€ì‹œë³´ë“œ ë“±)
            await self._log_info_alert(alert)
    
    def generate_alert_summary(self, period: timedelta) -> Dict:
        """ì•Œë¦¼ ìš”ì•½ ìƒì„±"""
        cutoff_time = datetime.now() - period
        recent_alerts = [
            a for a in self.alert_history 
            if a["timestamp"] > cutoff_time
        ]
        
        summary = {
            "period": period,
            "total_alerts": len(recent_alerts),
            "by_level": Counter(a["level"].value for a in recent_alerts),
            "by_rule": Counter(a["rule"] for a in recent_alerts),
            "critical_alerts": [
                a for a in recent_alerts 
                if a["level"] == AlertLevel.CRITICAL
            ],
            "trends": self._analyze_alert_trends(recent_alerts)
        }
        
        return summary
```

## 11. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 11.1 API ë³´ì•ˆ
- API í‚¤ ì•”í˜¸í™” ì €ì¥ (í™˜ê²½ë³€ìˆ˜ + KMS)
- Rate limiting êµ¬í˜„
- IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸
- API í˜¸ì¶œ ê°ì‚¬ ë¡œê·¸

### 11.2 ë°ì´í„° ë³´ì•ˆ
- ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹
- ë°ì´í„°ë² ì´ìŠ¤ ì•”í˜¸í™” (at rest)
- SSL/TLS í†µì‹ 
- ì •ê¸°ì  ë³´ì•ˆ ê°ì‚¬

### 11.3 ì ‘ê·¼ ì œì–´
- Role-based access control (RBAC)
- ë„êµ¬ë³„ ê¶Œí•œ ê´€ë¦¬
- ì„¸ì…˜ ê´€ë¦¬ ë° íƒ€ì„ì•„ì›ƒ
- 2ì°¨ ì¸ì¦ (2FA)

## 12. ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 12.1 ì¿¼ë¦¬ ìµœì í™”
- ì ì ˆí•œ ì¸ë±ìŠ¤ ì„¤ê³„
- íŒŒí‹°ì…”ë‹ ì „ëµ (ì¼ë³„/ì›”ë³„)
- ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
- ì—°ê²° í’€ë§

### 12.2 ìºì‹± ì „ëµ
- ë‹¤ì¸µ ìºì‹± (ë©”ëª¨ë¦¬ + Redis)
- ìºì‹œ ì›Œë°ì—…
- ìºì‹œ ë¬´íš¨í™” ì „ëµ
- TTL ìµœì í™”

### 12.3 ë¹„ë™ê¸° ì²˜ë¦¬
- ë…¼ë¸”ë¡œí‚¹ I/O
- ë°°ì¹˜ ì²˜ë¦¬
- ì‘ì—… í í™œìš©
- ë³‘ë ¬ ì²˜ë¦¬

ì´ ê³„íšì„œë¥¼ í†µí•´ íˆ¬ììë³„ ë§¤ë§¤ ë™í–¥ì„ ì •í™•í•˜ê³  ì‹ ì†í•˜ê²Œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” MCP ì„œë²„ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.